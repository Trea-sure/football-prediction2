# ==================== è¶³çƒæ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ v5.2 - äº‘ç«¯ç‰ˆ ====================
# ä¼˜åŒ–ï¼šä½¿ç”¨requestsä»£æ›¿Seleniumï¼Œé€‚åˆäº‘ç«¯éƒ¨ç½²

import streamlit as st
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import re
import time
import json
import os
import pickle
from collections import defaultdict
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# æ·±åº¦å­¦ä¹ 
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    from tensorflow.keras.optimizers import Adam
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# æœºå™¨å­¦ä¹ 
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# å¯è§†åŒ–
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ==================== é…ç½® ====================

@dataclass
class Config:
    DATA_FILE: str = "/tmp/football_training_data.json"
    MODEL_DIR: str = "/tmp/models_v5"
    MIN_TRAIN_SAMPLES: int = 30

    def __post_init__(self):
        os.makedirs(self.MODEL_DIR, exist_ok=True)

CONFIG = Config()

# ==================== æ•°æ®æŒä¹…åŒ–ç®¡ç† ====================

class DataPersistence:
    """æ•°æ®æŒä¹…åŒ–ç®¡ç†å™¨ - äº‘ç«¯ç‰ˆ"""

    def __init__(self):
        self.data = []

    def save_data(self, data):
        """ä¿å­˜æ•°æ®åˆ°äº‘ç«¯å­˜å‚¨"""
        try:
            with open(CONFIG.DATA_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False

    def load_data(self):
        """ä»äº‘ç«¯å­˜å‚¨åŠ è½½æ•°æ®"""
        if os.path.exists(CONFIG.DATA_FILE):
            try:
                with open(CONFIG.DATA_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return []

# ==================== æ•°æ®é‡‡é›†æ¨¡å—ï¼ˆäº‘ç«¯ç‰ˆ-ä½¿ç”¨requestsï¼‰ ====================

class DataCollector:
    """äº‘ç«¯ç‰ˆæ•°æ®é‡‡é›†å™¨ï¼Œä½¿ç”¨requestsä»£æ›¿Selenium"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.base_urls = {
            'live': "https://live.500.com/",
            'europe': "https://odds.500.com/fenxi/ouzhi-{}.shtml",
            'handicap': "https://odds.500.com/fenxi/rangqiu-{}.shtml",
            'asia': "https://odds.500.com/fenxi/yazhi-{}.shtml",
            'daxiao': "https://odds.500.com/fenxi/daxiao-{}.shtml"
        }
        self.log_callback = None

    def set_log_callback(self, callback):
        self.log_callback = callback

    def _log(self, message):
        if self.log_callback:
            self.log_callback(message)
        print(message)

    def get_page(self, url, wait=3):
        """ä½¿ç”¨requestsè·å–é¡µé¢"""
        try:
            response = self.session.get(url, timeout=30)
            response.encoding = 'gb2312'
            time.sleep(wait)
            return response.text
        except Exception as e:
            self._log(f"è·å–é¡µé¢å¤±è´¥: {str(e)[:50]}")
            return None

    def fetch_matches_by_date(self, date_str: str, only_finished: bool = True) -> pd.DataFrame:
        """ã€äº‘ç«¯ç‰ˆã€‘è·å–æŒ‡å®šæ—¥æœŸçš„æ¯”èµ›æ•°æ®"""
        from bs4 import BeautifulSoup

        html = self.get_page(f"{self.base_urls['live']}?e={date_str}", wait=4)
        if not html:
            return pd.DataFrame()

        soup = BeautifulSoup(html, 'lxml')
        matches = []

        for idx, tr in enumerate(soup.find_all('tr', id=re.compile(r'^a\d+$'))):
            try:
                match_id_full = tr.get('id', '')
                match_id = match_id_full.replace('a', '') if match_id_full else ''
                if not match_id or not match_id.isdigit():
                    continue

                tds = tr.find_all('td')
                if len(tds) < 8:
                    continue

                status_code = tr.get('status', '')
                row_text = tr.get_text()

                status = "æœª"
                if status_code == '4' or 'å®Œ' in row_text:
                    status = "å®Œ"
                elif status_code == '2' or 'è¿›è¡Œä¸­' in row_text:
                    status = "è¿›è¡Œä¸­"

                if only_finished and status != "å®Œ":
                    continue

                league = tds[1].get_text(strip=True) if len(tds) > 1 else ""

                match_time = ""
                if len(tds) > 3:
                    time_text = tds[3].get_text(strip=True)
                    time_match = re.search(r'(\d{2}:\d{2})', time_text)
                    if time_match:
                        match_time = time_match.group(1)

                # æå–æ¯”åˆ†
                score_home, score_away, actual_result = "", "", ""
                if status == "å®Œ":
                    pk_div = tr.find("div", class_="pk")
                    if pk_div:
                        all_links = pk_div.find_all("a")
                        if len(all_links) >= 3:
                            try:
                                home_val = int(all_links[0].get_text(strip=True))
                                away_val = int(all_links[2].get_text(strip=True))
                                if 0 <= home_val <= 20 and 0 <= away_val <= 20:
                                    score_home = str(home_val)
                                    score_away = str(away_val)

                                    if home_val > away_val:
                                        actual_result = "ä¸»èƒœ"
                                    elif home_val < away_val:
                                        actual_result = "å®¢èƒœ"
                                    else:
                                        actual_result = "å¹³å±€"
                            except:
                                pass

                # æå–çƒé˜Ÿ
                teams = []
                for t_idx in [5, 7]:
                    if t_idx < len(tds):
                        links = tds[t_idx].find_all('a')
                        for link in links:
                            name = link.get_text(strip=True)
                            if name and len(name) > 1 and not re.match(r'^\d+(\.\d+)?$', name):
                                if name not in teams:
                                    teams.append(name)
                                    break

                if len(teams) < 2:
                    for td in tds[2:]:
                        text = td.get_text(strip=True)
                        if (2 <= len(text) <= 15 and 
                            not any(c.isdigit() for c in text) and
                            text not in ['ä¸»', 'å®¢', 'vs', '-', ':']):
                            if text not in teams:
                                teams.append(text)
                        if len(teams) >= 2:
                            break

                teams = teams[:2]

                if len(teams) >= 2:
                    matches.append({
                        'order': idx,
                        'match_id': match_id,
                        'date': date_str,
                        'league': league or 'æœªçŸ¥',
                        'time': match_time,
                        'status': status,
                        'home_team': teams[0],
                        'away_team': teams[1],
                        'score': f"{score_home}-{score_away}" if score_home and score_away else "",
                        'score_home': score_home,
                        'score_away': score_away,
                        'actual_result': actual_result,
                        'has_result': status == "å®Œ" and actual_result != ""
                    })

            except Exception as e:
                continue

        df = pd.DataFrame(matches)
        if not df.empty:
            df = df.sort_values('order').reset_index(drop=True)
        return df

    def fetch_odds_from_page(self, match_id: str, odds_type: str = 'europe') -> List[Dict]:
        """ã€äº‘ç«¯ç‰ˆã€‘ä»é¡µé¢æå–èµ”ç‡æ•°æ®"""
        from bs4 import BeautifulSoup

        url = self.base_urls[odds_type].format(match_id)
        self._log(f"ğŸ“¡ {url}")

        html = self.get_page(url, wait=2)
        if not html:
            return []

        soup = BeautifulSoup(html, 'lxml')
        companies = []

        try:
            # æŸ¥æ‰¾éšè—çš„inputå…ƒç´ 
            row_input = soup.find('input', {'name': 'row'})
            if row_input:
                row_value = row_input.get('value', '')
                if row_value:
                    company_rows = row_value.split('|')

                    for row in company_rows:
                        if not row or 'å…¬å¸' in row or 'å¹³å‡' in row:
                            continue

                        parts = row.split(',')
                        if len(parts) >= 7:
                            try:
                                company = {
                                    'company': parts[0].strip(),
                                    'init_home': float(parts[1]),
                                    'init_draw': float(parts[2]),
                                    'init_away': float(parts[3]),
                                    'live_home': float(parts[4]),
                                    'live_draw': float(parts[5]),
                                    'live_away': float(parts[6]),
                                }
                                company['change_home'] = round(company['live_home'] - company['init_home'], 2)
                                company['change_draw'] = round(company['live_draw'] - company['init_draw'], 2)
                                company['change_away'] = round(company['live_away'] - company['init_away'], 2)
                                companies.append(company)
                            except:
                                continue
        except Exception as e:
            self._log(f"âŒ æå–èµ”ç‡å¤±è´¥: {str(e)[:50]}")

        return companies

    def fetch_all_odds(self, match_id: str, log_callback=None) -> Dict:
        """ã€äº‘ç«¯ç‰ˆã€‘è·å–æ‰€æœ‰å››ç§èµ”ç‡"""
        if log_callback:
            self.set_log_callback(log_callback)

        odds_data = {
            'europe': [],
            'asia': [],
            'handicap': [],
            'daxiao': []
        }

        self._log(f"ğŸ”„ å¼€å§‹è·å–æ¯”èµ› {match_id} çš„4ç§èµ”ç‡...")

        for i, (odds_type, name) in enumerate([
            ('europe', 'æ¬§æ´²èµ”ç‡'),
            ('asia', 'äºšç›˜'),
            ('handicap', 'è®©çƒ'),
            ('daxiao', 'å¤§å°çƒ')
        ], 1):
            self._log(f"ğŸ“Š [{i}/4] å¼€å§‹è·å–{name}...")
            try:
                odds_data[odds_type] = self.fetch_odds_from_page(match_id, odds_type)
                self._log(f"âœ“ [{i}/4] {name}: {len(odds_data[odds_type])} å®¶å…¬å¸")
            except Exception as e:
                self._log(f"âŒ [{i}/4] {name}è·å–å¤±è´¥: {str(e)[:50]}")
            time.sleep(0.5)

        total = sum(len(v) for v in odds_data.values())
        self._log(f"âœ… æ€»è®¡: {total} æ¡èµ”ç‡æ•°æ®")

        return odds_data

    def batch_fetch_history(self, start_date: str, days: int = 7, progress_callback=None, log_callback=None) -> pd.DataFrame:
        """ã€äº‘ç«¯ç‰ˆã€‘æ‰¹é‡è·å–å†å²æ•°æ®"""
        if log_callback:
            self.set_log_callback(log_callback)

        all_matches = []
        start = datetime.strptime(start_date, '%Y-%m-%d')

        for i in range(days):
            current_date = start - timedelta(days=i)
            date_str = current_date.strftime('%Y-%m-%d')

            self._log(f"ğŸ“… è·å– {date_str} çš„æ¯”èµ›...")

            if progress_callback:
                progress_callback(i+1, days, date_str, "è·å–æ¯”èµ›åˆ—è¡¨...")

            matches = self.fetch_matches_by_date(date_str, only_finished=True)

            if not matches.empty:
                self._log(f"ğŸ“ æ‰¾åˆ° {len(matches)} åœºå®Œèµ›æ¯”èµ›")

                if progress_callback:
                    progress_callback(i+1, days, date_str, f"è·å– {len(matches)} åœºæ¯”èµ›èµ”ç‡...")

                match_list = []
                for idx, row in matches.iterrows():
                    if progress_callback:
                        progress_callback(i+1, days, date_str, f"[{idx+1}/{len(matches)}] {row['home_team']} vs {row['away_team']}")

                    odds = self.fetch_all_odds(row['match_id'], log_callback)

                    match_data = row.to_dict()
                    match_data.update(odds)
                    match_list.append(match_data)

                    time.sleep(0.2)

                all_matches.extend(match_list)
                self._log(f"âœ… {date_str} å®Œæˆï¼Œå…± {len(match_list)} åœº")
            else:
                self._log(f"âš ï¸ {date_str} æ— å®Œèµ›æ•°æ®")

            time.sleep(0.5)

        df = pd.DataFrame(all_matches)
        if not df.empty:
            df = df.sort_values(['date', 'order']).reset_index(drop=True)
        return df

    def fetch_future_matches(self, date_str: str) -> pd.DataFrame:
        """ã€äº‘ç«¯ç‰ˆã€‘è·å–æœªæ¥æ¯”èµ›"""
        from bs4 import BeautifulSoup

        html = self.get_page(f"{self.base_urls['live']}?e={date_str}", wait=4)
        if not html:
            return pd.DataFrame()

        soup = BeautifulSoup(html, 'lxml')
        matches = []

        for idx, tr in enumerate(soup.find_all('tr', id=re.compile(r'^a\d+$'))):
            try:
                match_id_full = tr.get('id', '')
                match_id = match_id_full.replace('a', '') if match_id_full else ''
                if not match_id or not match_id.isdigit():
                    continue

                tds = tr.find_all('td')
                if len(tds) < 8:
                    continue

                status_code = tr.get('status', '')
                row_text = tr.get_text()

                status = "æœª"
                if status_code == '4' or 'å®Œ' in row_text:
                    status = "å®Œ"
                elif status_code == '2' or 'è¿›è¡Œä¸­' in row_text:
                    status = "è¿›è¡Œä¸­"

                if status == "å®Œ":
                    continue

                league = tds[1].get_text(strip=True) if len(tds) > 1 else ""

                match_time = ""
                if len(tds) > 3:
                    time_text = tds[3].get_text(strip=True)
                    time_match = re.search(r'(\d{2}:\d{2})', time_text)
                    if time_match:
                        match_time = time_match.group(1)

                teams = []
                for t_idx in [5, 7]:
                    if t_idx < len(tds):
                        links = tds[t_idx].find_all('a')
                        for link in links:
                            name = link.get_text(strip=True)
                            if name and len(name) > 1 and not re.match(r'^\d+(\.\d+)?$', name):
                                if name not in teams:
                                    teams.append(name)
                                    break

                if len(teams) < 2:
                    for td in tds[2:]:
                        text = td.get_text(strip=True)
                        if (2 <= len(text) <= 15 and 
                            not any(c.isdigit() for c in text) and
                            text not in ['ä¸»', 'å®¢', 'vs', '-', ':']):
                            if text not in teams:
                                teams.append(text)
                        if len(teams) >= 2:
                            break

                teams = teams[:2]

                if len(teams) >= 2:
                    matches.append({
                        'order': idx,
                        'match_id': match_id,
                        'date': date_str,
                        'league': league or 'æœªçŸ¥',
                        'time': match_time,
                        'status': status,
                        'home_team': teams[0],
                        'away_team': teams[1],
                        'score': "",
                        'score_home': "",
                        'score_away': "",
                        'actual_result': "",
                        'has_result': False
                    })

            except Exception as e:
                continue

        df = pd.DataFrame(matches)
        if not df.empty:
            df = df.sort_values('order').reset_index(drop=True)
        return df

    def fetch_future_matches_with_odds(self, date_str: str, progress_callback=None, log_callback=None) -> pd.DataFrame:
        """ã€äº‘ç«¯ç‰ˆã€‘è·å–æœªæ¥æ¯”èµ›å¹¶è·å–èµ”ç‡"""
        if log_callback:
            self.set_log_callback(log_callback)

        self._log(f"ğŸ”® è·å– {date_str} çš„æœªæ¥æ¯”èµ›...")

        matches = self.fetch_future_matches(date_str)
        if matches.empty:
            self._log(f"âš ï¸ {date_str} æ²¡æœ‰æœªæ¥æ¯”èµ›")
            return pd.DataFrame()

        self._log(f"ğŸ“ æ‰¾åˆ° {len(matches)} åœºæœªæ¥æ¯”èµ›")

        match_list = []
        for idx, row in matches.iterrows():
            if progress_callback:
                progress_callback(idx+1, len(matches), date_str, f"{row['home_team']} vs {row['away_team']}")

            self._log(f"ğŸ“Š è·å–èµ”ç‡: {row['home_team']} vs {row['away_team']}")

            odds = self.fetch_all_odds(row['match_id'], log_callback)

            match_data = row.to_dict()
            match_data.update(odds)
            match_list.append(match_data)

            time.sleep(0.2)

        df = pd.DataFrame(match_list)
        if not df.empty:
            df = df.sort_values('order').reset_index(drop=True)

        self._log(f"âœ… {date_str} å®Œæˆï¼Œå…± {len(df)} åœº")
        return df

# ==================== ç‰¹å¾å·¥ç¨‹ ====================

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹ - äº‘ç«¯ç‰ˆ"""

    FEATURE_DIM = 85

    def __init__(self):
        self.scaler = StandardScaler()
        self.is_fitted = False

    def extract_features(self, match_data: Dict) -> np.ndarray:
        """æå–ç‰¹å¾"""
        features = []

        europe = match_data.get('europe', [])
        features.extend(self._europe_features(europe))

        asia = match_data.get('asia', [])
        features.extend(self._asia_features(asia))

        handicap = match_data.get('handicap', [])
        features.extend(self._handicap_features(handicap))

        daxiao = match_data.get('daxiao', [])
        features.extend(self._daxiao_features(daxiao))

        features.extend(self._meta_features(match_data))

        if len(features) > self.FEATURE_DIM:
            features = features[:self.FEATURE_DIM]
        elif len(features) < self.FEATURE_DIM:
            features.extend([0.0] * (self.FEATURE_DIM - len(features)))

        return np.array(features)

    def _europe_features(self, europe_odds):
        """æ¬§æ´²èµ”ç‡ç‰¹å¾"""
        if not europe_odds or len(europe_odds) == 0:
            return [0.0] * 35

        try:
            df = pd.DataFrame(europe_odds)
            features = []

            for col in ['live_home', 'live_draw', 'live_away']:
                if col in df.columns and len(df) > 0:
                    features.extend([
                        float(df[col].mean()), 
                        float(df[col].std()) if len(df) > 1 else 0.0, 
                        float(df[col].min()), 
                        float(df[col].max()), 
                        float(df[col].median())
                    ])
                else:
                    features.extend([0.0] * 5)

            for col in ['change_home', 'change_draw', 'change_away']:
                if col in df.columns and len(df) > 0:
                    features.extend([
                        float(df[col].mean()),
                        (df[col] < 0).sum() / len(df) if len(df) > 0 else 0.0
                    ])
                else:
                    features.extend([0.0, 0.0])

            if 'live_home' in df.columns and 'live_draw' in df.columns and 'live_away' in df.columns:
                total_prob = 1/df['live_home'] + 1/df['live_draw'] + 1/df['live_away']
                features.extend([
                    float(total_prob.mean()),
                    float(total_prob.std()) if len(total_prob) > 1 else 0.0,
                    float((1/df['live_home']).mean()),
                    float((1/df['live_draw']).mean()),
                    float((1/df['live_away']).mean()),
                    float((1/df['live_home']).std()) if len(df) > 1 else 0.0,
                    float((1/df['live_draw']).std()) if len(df) > 1 else 0.0,
                    float((1/df['live_away']).std()) if len(df) > 1 else 0.0,
                    (total_prob > 1.1).sum() / len(df),
                    (total_prob < 0.95).sum() / len(df),
                    float(df['live_home'].mean() / df['live_away'].mean()) if df['live_away'].mean() != 0 else 1.0,
                    float((df['live_home'] < df['live_away']).sum() / len(df)),
                    float(df['live_draw'].mean()),
                    float(len(df))
                ])
            else:
                features.extend([0.0] * 14)

            return features[:35]
        except Exception as e:
            return [0.0] * 35

    def _asia_features(self, asia_odds):
        """äºšç›˜ç‰¹å¾"""
        if not asia_odds or len(asia_odds) == 0:
            return [0.0] * 15

        try:
            df = pd.DataFrame(asia_odds)
            features = []

            for col in ['live_home', 'live_away']:
                if col in df.columns and len(df) > 0:
                    features.extend([
                        float(df[col].mean()), 
                        float(df[col].std()) if len(df) > 1 else 0.0, 
                        float(df[col].min()), 
                        float(df[col].max())
                    ])
                else:
                    features.extend([0.0] * 4)

            if 'live_handicap' in df.columns:
                handicaps = []
                for h in df['live_handicap']:
                    try:
                        h_str = str(h).replace('çƒ', '').replace('åŠ', '.5').replace('å¹³', '0')
                        handicaps.append(float(h_str))
                    except:
                        handicaps.append(0)

                if len(handicaps) > 0:
                    features.extend([
                        float(np.mean(handicaps)),
                        float(np.std(handicaps)) if len(handicaps) > 1 else 0.0,
                        float(max(handicaps)),
                        float(min(handicaps)),
                        (np.array(handicaps) > 0).sum() / len(handicaps),
                        (np.array(handicaps) < 0).sum() / len(handicaps),
                        len(set(handicaps)) / len(handicaps) if len(handicaps) > 0 else 0
                    ])
                else:
                    features.extend([0.0] * 7)
            else:
                features.extend([0.0] * 7)

            return features[:15]
        except Exception as e:
            return [0.0] * 15

    def _handicap_features(self, handicap_odds):
        """è®©çƒç‰¹å¾"""
        if not handicap_odds or len(handicap_odds) == 0:
            return [0.0] * 10

        try:
            df = pd.DataFrame(handicap_odds)
            features = []

            for col in ['live_home', 'live_draw', 'live_away']:
                if col in df.columns and len(df) > 0:
                    features.extend([
                        float(df[col].mean()), 
                        float(df[col].std()) if len(df) > 1 else 0.0, 
                        float(df[col].min()), 
                        float(df[col].max())
                    ])
                else:
                    features.extend([0.0] * 4)

            if 'live_home' in df.columns and 'live_away' in df.columns and len(df) > 0:
                features.extend([
                    (df['live_home'] < df['live_away']).sum() / len(df),
                    (df['live_home'] > df['live_away']).sum() / len(df)
                ])
            else:
                features.extend([0.0, 0.0])

            return features[:10]
        except Exception as e:
            return [0.0] * 10

    def _daxiao_features(self, daxiao_odds):
        """å¤§å°çƒç‰¹å¾"""
        if not daxiao_odds or len(daxiao_odds) == 0:
            return [0.0] * 12

        try:
            df = pd.DataFrame(daxiao_odds)
            features = []

            for col in ['live_over', 'live_under']:
                if col in df.columns and len(df) > 0:
                    features.extend([
                        float(df[col].mean()), 
                        float(df[col].std()) if len(df) > 1 else 0.0, 
                        float(df[col].min()), 
                        float(df[col].max())
                    ])
                else:
                    features.extend([0.0] * 4)

            if 'live_line' in df.columns:
                lines = []
                for line in df['live_line']:
                    try:
                        line_str = str(line).replace('çƒ', '').replace('åŠ', '.5')
                        lines.append(float(line_str))
                    except:
                        lines.append(2.5)

                if len(lines) > 0:
                    features.extend([
                        float(np.mean(lines)),
                        float(np.std(lines)) if len(lines) > 1 else 0.0,
                        float(max(lines)),
                        float(min(lines))
                    ])
                else:
                    features.extend([0.0] * 4)
            else:
                features.extend([0.0] * 4)

            return features[:12]
        except Exception as e:
            return [0.0] * 12

    def _meta_features(self, match_data):
        """å…ƒç‰¹å¾"""
        features = []

        league = match_data.get('league', '')
        tier = 3
        if any(x in league for x in ['è‹±è¶…','è¥¿ç”²','æ„ç”²','å¾·ç”²','æ³•ç”²','æ¬§å† ']): tier = 1
        elif any(x in league for x in ['è·ç”²','è‘¡è¶…','ä¿„è¶…','æ¯”ç”²','æ¬§ç½—å·´']): tier = 2
        features.append(float(tier))

        match_time = match_data.get('time', '15:00')
        try:
            hour = int(match_time.split(':')[0])
            features.extend([
                float(np.sin(2 * np.pi * hour / 24)),
                float(np.cos(2 * np.pi * hour / 24)),
                1.0 if 19 <= hour <= 23 else 0.0,
                1.0 if hour < 12 else 0.0
            ])
        except:
            features.extend([0.0, 0.0, 0.0, 0.0])

        europe = match_data.get('europe', [])
        if europe and len(europe) > 0:
            try:
                df = pd.DataFrame(europe)
                if 'live_home' in df.columns and 'live_away' in df.columns:
                    avg_home = df['live_home'].mean()
                    avg_away = df['live_away'].mean()
                    features.extend([
                        float(1/avg_home) if avg_home > 0 else 0.5,
                        float(1/avg_away) if avg_away > 0 else 0.5,
                        float(avg_away / avg_home) if avg_home > 0 else 1.0,
                        float((avg_home < avg_away).sum() / len(df)) if len(df) > 0 else 0.5
                    ])
                else:
                    features.extend([0.5, 0.5, 1.0, 0.5])
            except:
                features.extend([0.5, 0.5, 1.0, 0.5])
        else:
            features.extend([0.5, 0.5, 1.0, 0.5])

        for odds_type in ['europe', 'asia', 'handicap', 'daxiao']:
            odds = match_data.get(odds_type, [])
            features.append(float(len(odds)) if odds else 0.0)

        return features[:13]

    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        X, y_labels, metadata = [], [], []

        for _, row in df.iterrows():
            if not row.get('actual_result') or row['actual_result'] not in ['ä¸»èƒœ', 'å¹³å±€', 'å®¢èƒœ']:
                continue

            has_odds = any(len(row.get(ot, []) or []) > 0 for ot in ['europe', 'asia', 'handicap', 'daxiao'])
            if not has_odds:
                continue

            features = self.extract_features(row.to_dict())

            if len(features) != self.FEATURE_DIM:
                if len(features) > self.FEATURE_DIM:
                    features = features[:self.FEATURE_DIM]
                else:
                    features = np.concatenate([features, np.zeros(self.FEATURE_DIM - len(features))])

            X.append(features)

            result = row['actual_result']
            if result == 'ä¸»èƒœ':
                y_labels.append(0)
            elif result == 'å¹³å±€':
                y_labels.append(1)
            else:
                y_labels.append(2)

            metadata.append({
                'match_id': row['match_id'],
                'teams': f"{row['home_team']} vs {row['away_team']}",
                'date': row['date'],
                'league': row['league']
            })

        if len(X) == 0:
            return np.array([]), np.array([]), []

        X = np.array(X)
        y_labels = np.array(y_labels)

        y_onehot = np.zeros((len(y_labels), 3))
        for i, label in enumerate(y_labels):
            y_onehot[i, label] = 1

        if not self.is_fitted:
            X = self.scaler.fit_transform(X)
            self.is_fitted = True
        else:
            X = self.scaler.transform(X)

        return X, y_onehot, metadata

    def transform(self, match_data: Dict) -> np.ndarray:
        features = self.extract_features(match_data)

        if len(features) != self.FEATURE_DIM:
            if len(features) > self.FEATURE_DIM:
                features = features[:self.FEATURE_DIM]
            else:
                features = np.concatenate([features, np.zeros(self.FEATURE_DIM - len(features))])

        if self.is_fitted:
            features = self.scaler.transform(features.reshape(1, -1))[0]
        return features

    def save(self, path):
        with open(path, 'wb') as f:
            pickle.dump({'scaler': self.scaler, 'is_fitted': self.is_fitted}, f)

    def load(self, path):
        with open(path, 'rb') as f:
            data = pickle.load(f)
            self.scaler = data['scaler']
            self.is_fitted = data['is_fitted']

# ==================== æ·±åº¦å­¦ä¹ æ¨¡å‹ ====================

class DeepLearningModel:
    """æ·±åº¦å­¦ä¹ æ¨¡å‹ - äº‘ç«¯ç‰ˆ"""

    def __init__(self, input_dim=85):
        self.input_dim = input_dim
        self.dnn_model = None
        self.rf_model = None
        self.gbdt_model = None
        self.is_trained = False
        self.training_history = []

    def build_models(self):
        if TF_AVAILABLE:
            self.dnn_model = self._build_dnn()

        self.rf_model = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=5, random_state=42, n_jobs=-1)
        self.gbdt_model = GradientBoostingClassifier(n_estimators=150, learning_rate=0.05, max_depth=6, random_state=42)

    def _build_dnn(self):
        model = Sequential([
            Dense(256, activation='relu', input_shape=(self.input_dim,)),
            BatchNormalization(),
            Dropout(0.4),
            Dense(128, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            Dense(64, activation='relu'),
            BatchNormalization(),
            Dropout(0.2),
            Dense(3, activation='softmax')
        ])

        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
        return model

    def train(self, X, y, validation_split=0.2, epochs=100):
        if len(X) < 10:
            return False, "æ•°æ®é‡ä¸è¶³"

        results = {}
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)

        if TF_AVAILABLE and self.dnn_model:
            callbacks = [
                EarlyStopping(patience=15, restore_best_weights=True, monitor='val_accuracy'),
                ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)
            ]
            history = self.dnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), 
                                        epochs=epochs, batch_size=32, callbacks=callbacks, verbose=0)
            results['dnn'] = {
                'train_acc': max(history.history['accuracy']),
                'val_acc': max(history.history['val_accuracy'])
            }
            self.training_history.append(history.history)

        y_train_labels = np.argmax(y_train, axis=1)
        y_val_labels = np.argmax(y_val, axis=1)

        self.rf_model.fit(X_train, y_train_labels)
        results['rf'] = {
            'train_acc': self.rf_model.score(X_train, y_train_labels),
            'val_acc': self.rf_model.score(X_val, y_val_labels)
        }

        self.gbdt_model.fit(X_train, y_train_labels)
        results['gbdt'] = {
            'train_acc': self.gbdt_model.score(X_train, y_train_labels),
            'val_acc': self.gbdt_model.score(X_val, y_val_labels)
        }

        self.is_trained = True
        return True, results

    def predict(self, X):
        """é¢„æµ‹ - åŒ…æ‹¬èƒœå¹³è´Ÿã€æ¯”åˆ†ã€æ€»è¿›çƒæ•°"""
        if not self.is_trained:
            return None

        dnn_pred = None
        if TF_AVAILABLE and self.dnn_model:
            dnn_pred = self.dnn_model.predict(X.reshape(1, -1), verbose=0)[0]

        rf_pred = self.rf_model.predict_proba(X.reshape(1, -1))[0]
        gbdt_pred = self.gbdt_model.predict_proba(X.reshape(1, -1))[0]

        if dnn_pred is not None:
            ensemble_pred = 0.4 * dnn_pred + 0.3 * rf_pred + 0.3 * gbdt_pred
        else:
            ensemble_pred = 0.5 * rf_pred + 0.5 * gbdt_pred

        ensemble_pred = ensemble_pred / ensemble_pred.sum()

        labels = ['ä¸»èƒœ', 'å¹³å±€', 'å®¢èƒœ']

        top3_indices = np.argsort(ensemble_pred)[-3:][::-1]
        top3_results = [(labels[i], round(ensemble_pred[i] * 100, 2)) for i in top3_indices]

        home_win_prob = ensemble_pred[0]
        draw_prob = ensemble_pred[1]
        away_win_prob = ensemble_pred[2]

        score_predictions = self._predict_scores(home_win_prob, draw_prob, away_win_prob)
        total_goals_predictions = self._predict_total_goals(home_win_prob, draw_prob, away_win_prob)

        return {
            'result': top3_results[0][0],
            'confidence': top3_results[0][1],
            'top3_results': top3_results,
            'probabilities': {labels[i]: round(ensemble_pred[i] * 100, 2) for i in range(3)},
            'score_predictions': score_predictions,
            'total_goals_predictions': total_goals_predictions
        }

    def _predict_scores(self, home_win_prob, draw_prob, away_win_prob):
        """é¢„æµ‹æœ€å¯èƒ½çš„3ä¸ªæ¯”åˆ†"""
        scores = []

        if home_win_prob > 0.3:
            scores.extend([
                ('1-0', home_win_prob * 0.25),
                ('2-0', home_win_prob * 0.20),
                ('2-1', home_win_prob * 0.18),
                ('3-0', home_win_prob * 0.12),
                ('3-1', home_win_prob * 0.10),
            ])

        if draw_prob > 0.2:
            scores.extend([
                ('1-1', draw_prob * 0.40),
                ('0-0', draw_prob * 0.30),
                ('2-2', draw_prob * 0.20),
            ])

        if away_win_prob > 0.3:
            scores.extend([
                ('0-1', away_win_prob * 0.25),
                ('0-2', away_win_prob * 0.20),
                ('1-2', away_win_prob * 0.18),
                ('0-3', away_win_prob * 0.12),
                ('1-3', away_win_prob * 0.10),
            ])

        score_dict = {}
        for score, weight in scores:
            if score in score_dict:
                score_dict[score] += weight
            else:
                score_dict[score] = weight

        sorted_scores = sorted(score_dict.items(), key=lambda x: x[1], reverse=True)
        top3 = sorted_scores[:3]

        total_weight = sum(w for _, w in top3) if top3 else 1
        return [(score, round(w/total_weight*100, 2)) for score, w in top3]

    def _predict_total_goals(self, home_win_prob, draw_prob, away_win_prob):
        """é¢„æµ‹æœ€å¯èƒ½çš„3ä¸ªæ€»è¿›çƒæ•°"""
        goals = []

        goals.extend([
            (0, draw_prob * 0.15 + (home_win_prob + away_win_prob) * 0.05),
            (1, (home_win_prob + away_win_prob) * 0.25),
            (2, draw_prob * 0.30 + (home_win_prob + away_win_prob) * 0.20),
            (3, draw_prob * 0.35 + (home_win_prob + away_win_prob) * 0.30),
            (4, draw_prob * 0.15 + (home_win_prob + away_win_prob) * 0.25),
            (5, (home_win_prob + away_win_prob) * 0.10),
            (6, (home_win_prob + away_win_prob) * 0.05),
        ])

        sorted_goals = sorted(goals, key=lambda x: x[1], reverse=True)
        top3 = sorted_goals[:3]

        total_weight = sum(w for _, w in top3) if top3 else 1
        return [(str(goals), round(w/total_weight*100, 2)) for goals, w in top3]

    def save(self, name='model_v5'):
        path = os.path.join(CONFIG.MODEL_DIR, name)
        os.makedirs(path, exist_ok=True)

        if TF_AVAILABLE and self.dnn_model:
            self.dnn_model.save(os.path.join(path, 'dnn.h5'))

        with open(os.path.join(path, 'rf.pkl'), 'wb') as f:
            pickle.dump(self.rf_model, f)
        with open(os.path.join(path, 'gbdt.pkl'), 'wb') as f:
            pickle.dump(self.gbdt_model, f)

        with open(os.path.join(path, 'config.pkl'), 'wb') as f:
            pickle.dump({'is_trained': self.is_trained, 'training_history': self.training_history}, f)

        return True

    def load(self, name='model_v5'):
        path = os.path.join(CONFIG.MODEL_DIR, name)

        if not os.path.exists(path):
            return False

        try:
            if TF_AVAILABLE and os.path.exists(os.path.join(path, 'dnn.h5')):
                self.dnn_model = load_model(os.path.join(path, 'dnn.h5'))

            with open(os.path.join(path, 'rf.pkl'), 'rb') as f:
                self.rf_model = pickle.load(f)
            with open(os.path.join(path, 'gbdt.pkl'), 'rb') as f:
                self.gbdt_model = pickle.load(f)

            with open(os.path.join(path, 'config.pkl'), 'rb') as f:
                config = pickle.load(f)
                self.is_trained = config['is_trained']
                self.training_history = config['training_history']

            return True
        except:
            return False

# ==================== ä¸»æ§åˆ¶ç³»ç»Ÿ ====================

class FootballPredictionSystem:
    """è¶³çƒé¢„æµ‹ä¸»ç³»ç»Ÿ - äº‘ç«¯ç‰ˆ"""

    def __init__(self):
        self.collector = DataCollector()
        self.feature_engineer = FeatureEngineer()
        self.model = DeepLearningModel(input_dim=FeatureEngineer.FEATURE_DIM)
        self.data_file = CONFIG.DATA_FILE

        self.df = self._load_data()

        if self.model.load():
            scaler_path = os.path.join(CONFIG.MODEL_DIR, 'scaler.pkl')
            if os.path.exists(scaler_path):
                self.feature_engineer.load(scaler_path)

    def _load_data(self):
        if os.path.exists(self.data_file):
            try:
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                df = pd.DataFrame(data)

                required_cols = ['match_id', 'date', 'league', 'time', 'home_team', 'away_team', 'actual_result']
                for col in required_cols:
                    if col not in df.columns:
                        df[col] = ''

                for col in ['europe', 'asia', 'daxiao', 'handicap']:
                    if col in df.columns:
                        df[col] = df[col].apply(lambda x: json.loads(x) if isinstance(x, str) else x if isinstance(x, list) else [])
                    else:
                        df[col] = [[] for _ in range(len(df))]

                return df
            except Exception as e:
                print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")

        return pd.DataFrame(columns=[
            'match_id', 'date', 'league', 'time', 'status', 'home_team', 'away_team',
            'score', 'score_home', 'score_away', 'actual_result', 'has_result',
            'europe', 'asia', 'daxiao', 'handicap', 'order'
        ])

    def _save_data(self):
        try:
            if self.df.empty:
                with open(self.data_file, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                return True

            df_copy = self.df.copy()
            for col in ['europe', 'asia', 'daxiao', 'handicap']:
                if col in df_copy.columns:
                    def serialize_odds(x):
                        if isinstance(x, list):
                            return json.dumps(x, ensure_ascii=False)
                        elif isinstance(x, str):
                            try:
                                json.loads(x)
                                return x
                            except:
                                return json.dumps([], ensure_ascii=False)
                        else:
                            return json.dumps([], ensure_ascii=False)

                    df_copy[col] = df_copy[col].apply(serialize_odds)

            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(df_copy.to_dict('records'), f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False

    def batch_collect_training_data(self, start_date: str, days: int = 7, progress_callback=None, log_callback=None):
        """æ‰¹é‡æ”¶é›†è®­ç»ƒæ•°æ®"""
        new_df = self.collector.batch_fetch_history(start_date, days, progress_callback, log_callback)

        if new_df.empty:
            return False, "æœªè·å–åˆ°æ•°æ®"

        if not self.df.empty and 'match_id' in self.df.columns:
            existing_ids = set(self.df['match_id'].tolist())
            new_df = new_df[~new_df['match_id'].isin(existing_ids)]

        if not new_df.empty:
            for col in self.df.columns:
                if col not in new_df.columns:
                    if col in ['europe', 'asia', 'daxiao', 'handicap']:
                        new_df[col] = [[] for _ in range(len(new_df))]
                    else:
                        new_df[col] = ['' for _ in range(len(new_df))]

            for col in new_df.columns:
                if col not in self.df.columns:
                    if col in ['europe', 'asia', 'daxiao', 'handicap']:
                        self.df[col] = [[] for _ in range(len(self.df))]
                    else:
                        self.df[col] = ['' for _ in range(len(self.df))]

            self.df = pd.concat([self.df, new_df], ignore_index=True)
            self._save_data()

            has_result = len(new_df[new_df['actual_result'] != ''])
            has_odds = len(new_df[new_df['europe'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)])

            return True, f"æ–°å¢ {len(new_df)} åœºï¼ˆæœ‰ç»“æœ: {has_result}åœºï¼Œæœ‰èµ”ç‡: {has_odds}åœºï¼‰ï¼Œç´¯è®¡ {len(self.df)} åœº"

        return True, "æ‰€æœ‰æ•°æ®å·²æ˜¯æœ€æ–°"

    def collect_future_matches(self, date_str: str, progress_callback=None, log_callback=None):
        """æ”¶é›†æœªæ¥æ¯”èµ›ç”¨äºé¢„æµ‹"""
        new_df = self.collector.fetch_future_matches_with_odds(date_str, progress_callback, log_callback)

        if new_df.empty:
            return False, "æœªè·å–åˆ°æœªæ¥æ¯”èµ›"

        if not self.df.empty and 'match_id' in self.df.columns:
            existing_ids = set(self.df['match_id'].tolist())
            new_df = new_df[~new_df['match_id'].isin(existing_ids)]

        if not new_df.empty:
            for col in self.df.columns:
                if col not in new_df.columns:
                    if col in ['europe', 'asia', 'daxiao', 'handicap']:
                        new_df[col] = [[] for _ in range(len(new_df))]
                    else:
                        new_df[col] = ['' for _ in range(len(new_df))]

            for col in new_df.columns:
                if col not in self.df.columns:
                    if col in ['europe', 'asia', 'daxiao', 'handicap']:
                        self.df[col] = [[] for _ in range(len(self.df))]
                    else:
                        self.df[col] = ['' for _ in range(len(self.df))]

            self.df = pd.concat([self.df, new_df], ignore_index=True)
            self._save_data()

            has_odds = len(new_df[new_df['europe'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)])

            return True, f"æ–°å¢ {len(new_df)} åœºæœªæ¥æ¯”èµ›ï¼ˆæœ‰èµ”ç‡: {has_odds}åœºï¼‰"

        return True, "æ‰€æœ‰æœªæ¥æ¯”èµ›å·²æ˜¯æœ€æ–°"

    def train_model(self):
        """è®­ç»ƒæ¨¡å‹"""
        if self.df.empty or 'actual_result' not in self.df.columns:
            return False, "æ²¡æœ‰è®­ç»ƒæ•°æ®"

        train_df = self.df[self.df['actual_result'].isin(['ä¸»èƒœ', 'å¹³å±€', 'å®¢èƒœ'])].copy()

        if len(train_df) < CONFIG.MIN_TRAIN_SAMPLES:
            return False, f"éœ€è¦è‡³å°‘{CONFIG.MIN_TRAIN_SAMPLES}åœºæœ‰ç»“æœçš„æ¯”èµ›ï¼Œå½“å‰{len(train_df)}åœº"

        has_odds_count = 0
        for idx, row in train_df.iterrows():
            for odds_type in ['europe', 'asia', 'handicap', 'daxiao']:
                odds = row.get(odds_type, [])
                if odds and len(odds) > 0:
                    has_odds_count += 1
                    break

        if has_odds_count == 0:
            return False, f"æœ‰ç»“æœçš„æ¯”èµ›: {len(train_df)}åœºï¼Œä½†æœ‰èµ”ç‡æ•°æ®çš„: 0åœºã€‚è¯·ç¡®ä¿æˆåŠŸè·å–äº†èµ”ç‡ä¿¡æ¯ã€‚"

        X, y, metadata = self.feature_engineer.prepare_training_data(train_df)

        if len(X) == 0:
            return False, f"ç‰¹å¾æå–å¤±è´¥ã€‚æœ‰èµ”ç‡çš„æ¯”èµ›: {has_odds_count}åœºï¼Œä½†æ— æ³•æå–æœ‰æ•ˆç‰¹å¾ã€‚"

        self.model.build_models()
        success, results = self.model.train(X, y)

        if success:
            self.model.save()
            self.feature_engineer.save(os.path.join(CONFIG.MODEL_DIR, 'scaler.pkl'))
            return True, results

        return False, results

    def predict(self, match_data):
        """é¢„æµ‹"""
        if not self.model.is_trained:
            return None, "æ¨¡å‹æœªè®­ç»ƒ"

        features = self.feature_engineer.transform(match_data)
        result = self.model.predict(features)
        return result, None

    def get_stats(self):
        """è·å–ç»Ÿè®¡"""
        if self.df.empty:
            return {'total': 0, 'trainable': 0, 'model_ready': self.model.is_trained}

        if 'actual_result' not in self.df.columns:
            trainable = 0
        else:
            has_result = self.df['actual_result'].isin(['ä¸»èƒœ', 'å¹³å±€', 'å®¢èƒœ'])

            has_odds = pd.Series([False] * len(self.df))
            for odds_type in ['europe', 'asia', 'handicap', 'daxiao']:
                if odds_type in self.df.columns:
                    has_odds |= self.df[odds_type].apply(
                        lambda x: len(x) > 0 if isinstance(x, list) else False
                    )

            trainable = len(self.df[has_result & has_odds])

        return {
            'total': len(self.df),
            'trainable': trainable,
            'model_ready': self.model.is_trained
        }

# ==================== Streamlit UI ====================

def main():
    st.set_page_config(page_title="âš½ è¶³çƒæ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ v5.2", layout="wide")

    st.markdown("""
    <style>
    .main-header { font-size: 2.5rem; font-weight: bold; color: #1f77b4; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<div class="main-header">âš½ è¶³çƒæ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ v5.2<br><small>äº‘ç«¯éƒ¨ç½²ç‰ˆ</small></div>', unsafe_allow_html=True)

    if 'system' not in st.session_state:
        with st.spinner("ç³»ç»Ÿåˆå§‹åŒ–ä¸­..."):
            st.session_state['system'] = FootballPredictionSystem()

    system = st.session_state['system']
    stats = system.get_stats()

    with st.sidebar:
        st.header("ğŸ›ï¸ æ§åˆ¶é¢æ¿")

        # è·å–æœªæ¥æ¯”èµ›
        st.subheader("è·å–æœªæ¥æ¯”èµ›ï¼ˆé¢„æµ‹ï¼‰")
        future_date = st.date_input("é€‰æ‹©æ¯”èµ›æ—¥æœŸ", datetime.now() + timedelta(days=1))

        if st.button("è·å–æœªæ¥æ¯”èµ›", use_container_width=True, type="primary"):
            st.session_state['fetch_logs'] = []

            progress_bar = st.progress(0)
            status_text = st.empty()

            def update_progress(current, total, date_str, status):
                progress_bar.progress(current / total if total > 0 else 0)
                status_text.text(f"[{current}/{total}] {status}")

            def add_log(message):
                st.session_state['fetch_logs'].append(message)
                if len(st.session_state['fetch_logs']) > 100:
                    st.session_state['fetch_logs'] = st.session_state['fetch_logs'][-100:]

            with st.spinner("è·å–æœªæ¥æ¯”èµ›ä¸­..."):
                success, msg = system.collect_future_matches(
                    future_date.strftime('%Y-%m-%d'),
                    update_progress,
                    add_log
                )

            progress_bar.empty()
            status_text.empty()

            if success:
                st.success(msg)
                st.balloons()
            else:
                st.error(msg)

            st.rerun()

        st.markdown("---")

        # æ‰¹é‡è·å–è®­ç»ƒæ•°æ®
        st.subheader("æ‰¹é‡è·å–è®­ç»ƒæ•°æ®")
        col_date, col_days = st.columns([2, 1])
        with col_date:
            start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=7))
        with col_days:
            days = st.number_input("å¤©æ•°", min_value=1, max_value=30, value=7)

        if st.button("æ‰¹é‡è·å–è®­ç»ƒæ•°æ®", use_container_width=True, type="primary"):
            st.session_state['fetch_logs'] = []

            progress_bar = st.progress(0)
            status_text = st.empty()

            def update_progress(current_day, total_days, date_str, status):
                progress_bar.progress(current_day / total_days)
                status_text.text(f"[{current_day}/{total_days}] {date_str}: {status}")

            def add_log(message):
                st.session_state['fetch_logs'].append(message)
                if len(st.session_state['fetch_logs']) > 100:
                    st.session_state['fetch_logs'] = st.session_state['fetch_logs'][-100:]

            with st.spinner("è·å–ä¸­..."):
                success, msg = system.batch_collect_training_data(
                    start_date.strftime('%Y-%m-%d'),
                    int(days),
                    update_progress,
                    add_log
                )

            progress_bar.empty()
            status_text.empty()

            if success:
                st.success(msg)
                st.balloons()
            else:
                st.error(msg)

            st.rerun()

        st.markdown("---")

        # æ¨¡å‹è®­ç»ƒ
        st.subheader("æ¨¡å‹è®­ç»ƒ")
        trainable_count = stats['trainable']

        if trainable_count >= CONFIG.MIN_TRAIN_SAMPLES:
            st.success(f"å¯è®­ç»ƒæ•°æ®: {trainable_count}åœº")
            if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹", use_container_width=True, type="primary"):
                with st.spinner("è®­ç»ƒä¸­..."):
                    success, result = system.train_model()
                    if success:
                        st.success("è®­ç»ƒå®Œæˆï¼")
                        st.json(result)
                    else:
                        st.error(result)
        else:
            st.warning(f"éœ€è¦{CONFIG.MIN_TRAIN_SAMPLES}åœºï¼Œå½“å‰{trainable_count}åœº")
            st.progress(trainable_count / CONFIG.MIN_TRAIN_SAMPLES if CONFIG.MIN_TRAIN_SAMPLES > 0 else 0)

        st.markdown("---")

        if st.button("ä¿å­˜æ•°æ®", use_container_width=True):
            if system._save_data():
                st.success("å·²ä¿å­˜")

        if st.button("æ¸…ç©ºæ•°æ®", use_container_width=True):
            system.df = pd.DataFrame(columns=[
                'match_id', 'date', 'league', 'time', 'status', 'home_team', 'away_team',
                'score', 'score_home', 'score_away', 'actual_result', 'has_result',
                'europe', 'asia', 'daxiao', 'handicap', 'order'
            ])
            system._save_data()
            st.success("å·²æ¸…ç©º")

    tabs = st.tabs(["æ•°æ®æ¦‚è§ˆ", "é¢„æµ‹ä¸­å¿ƒ"])

    with tabs[0]:
        st.subheader("è®­ç»ƒæ•°æ®æ¦‚è§ˆ")

        cols = st.columns(4)
        with cols[0]:
            st.metric("æ€»æ¯”èµ›æ•°", stats['total'])
        with cols[1]:
            st.metric("å¯è®­ç»ƒæ•°æ®", stats['trainable'])
        with cols[2]:
            st.metric("è®­ç»ƒé—¨æ§›", CONFIG.MIN_TRAIN_SAMPLES)
        with cols[3]:
            st.metric("æ¨¡å‹çŠ¶æ€", "å°±ç»ª" if stats['model_ready'] else "æœªè®­ç»ƒ")

        if not system.df.empty:
            st.markdown("---")

            display_df = system.df.copy()
            if 'actual_result' in display_df.columns:
                has_result = display_df['actual_result'].isin(['ä¸»èƒœ', 'å¹³å±€', 'å®¢èƒœ'])
                display_df = display_df[has_result]

            display_cols = ['date', 'league', 'home_team', 'away_team', 'score', 'actual_result']
            display_cols = [c for c in display_cols if c in display_df.columns]

            def get_odds_status(row):
                odds_types = []
                for ot in ['europe', 'asia', 'handicap', 'daxiao']:
                    if ot in row and isinstance(row[ot], list) and len(row[ot]) > 0:
                        odds_types.append(ot[:2])
                return ','.join(odds_types) if odds_types else 'æ— '

            if not display_df.empty:
                display_df['odds'] = display_df.apply(get_odds_status, axis=1)
                display_cols.append('odds')

                st.dataframe(display_df[display_cols], use_container_width=True, height=400)
            else:
                st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
        else:
            st.info("æš‚æ— æ•°æ®ï¼Œè¯·ä½¿ç”¨ä¾§è¾¹æ è·å–è®­ç»ƒæ•°æ®")

    with tabs[1]:
        st.subheader("æ¯”èµ›é¢„æµ‹")

        if not system.df.empty and stats['model_ready']:
            future_matches = system.df[system.df['actual_result'] == ''] if 'actual_result' in system.df.columns else system.df

            if not future_matches.empty:
                selected = st.selectbox(
                    "é€‰æ‹©æ¯”èµ›è¿›è¡Œé¢„æµ‹",
                    future_matches.to_dict('records'),
                    format_func=lambda x: f"{x.get('date', 'N/A')} | {x.get('league', 'N/A')} | {x.get('home_team', 'N/A')} vs {x.get('away_team', 'N/A')}"
                )

                if selected:
                    col1, col2 = st.columns([2, 1])

                    with col1:
                        st.markdown(f"### {selected.get('home_team', 'N/A')} ğŸ†š {selected.get('away_team', 'N/A')}")
                        st.write(f"**è”èµ›:** {selected.get('league', 'N/A')}")

                        europe_odds = selected.get('europe', [])
                        has_odds = europe_odds and len(europe_odds) > 0
                        if has_odds:
                            st.write(f"**èµ”ç‡æ•°æ®:** å·²è·å– ({len(europe_odds)}å®¶å…¬å¸)")
                        else:
                            st.warning("æš‚æ— èµ”ç‡æ•°æ®")

                    with col2:
                        if has_odds:
                            if st.button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
                                result, error = system.predict(selected)
                                if error:
                                    st.error(error)
                                else:
                                    st.success(f"**é¢„æµ‹ç»“æœ: {result['result']}**")
                                    st.write(f"**ç½®ä¿¡åº¦:** {result['confidence']}%")

                                    st.markdown("**èƒœå¹³è´Ÿæ¦‚ç‡ Top 3:**")
                                    for i, (res, conf) in enumerate(result['top3_results'], 1):
                                        st.write(f"{i}. {res}: {conf}%")

                                    st.markdown("**æœ€å¯èƒ½æ¯”åˆ† Top 3:**")
                                    for i, (score, prob) in enumerate(result['score_predictions'], 1):
                                        st.write(f"{i}. {score}: {prob}%")

                                    st.markdown("**æ€»è¿›çƒæ•° Top 3:**")
                                    for i, (goals, prob) in enumerate(result['total_goals_predictions'], 1):
                                        st.write(f"{i}. {goals}çƒ: {prob}%")
                        else:
                            st.info("è¯·å…ˆè·å–èµ”ç‡æ•°æ®")
            else:
                st.info("å½“å‰æ²¡æœ‰æœªé¢„æµ‹çš„æ¯”èµ›ã€‚è¯·ä½¿ç”¨ä¾§è¾¹æ 'è·å–æœªæ¥æ¯”èµ›'åŠŸèƒ½è·å–å¾…é¢„æµ‹æ¯”èµ›ã€‚")
        else:
            if not stats['model_ready']:
                st.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            else:
                st.info("æš‚æ— æ¯”èµ›æ•°æ®ã€‚è¯·ä½¿ç”¨ä¾§è¾¹æ è·å–æ•°æ®")

if __name__ == "__main__":
    main()